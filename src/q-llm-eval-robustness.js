import { html } from "https://cdn.jsdelivr.net/npm/lit-html@3/lit-html.js";

export default async function ({ user, weight = 1 }) {
  const id = "q-llm-eval-robustness";
  const title = "LLM Eval â€“ Prompt Robustness";

  const answer = "llm-rubric";

  const question = html`
    <div class="mb-3">
      <p>
        A team is using PromptFoo to evaluate summaries generated by an LLM.
        Their current test only checks for keyword presence using
        <code>contains-all</code>.
      </p>

      <pre><code>
assertions:
  - contains-all:
      values:
        - "API"
        - "authentication"
      </code></pre>

      <p>
        During testing, the model sometimes <strong>hallucinates incorrect technical details</strong>
        while still passing this assertion.
      </p>

      <p>
        <strong>Which additional PromptFoo assertion is BEST suited</strong>
        to catch hallucinations while still allowing flexible wording?
      </p>

      <label class="form-label">Your answer (assertion name only):</label>
      <input class="form-control" id="${id}" name="${id}" />
    </div>
  `;

  return { id, title, weight, question, answer };
}
